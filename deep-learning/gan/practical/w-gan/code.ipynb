{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# WGAN with gradient penalty (WGAN-GP)\n",
    "* Paper Link: [https://arxiv.org/abs/1704.00028](https://arxiv.org/abs/1704.00028)\n",
    "* Best explained in this [blog](https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/) and math is explained better in this [video](https://www.youtube.com/watch?v=QJOEmwvnmTM) and this [video](https://www.youtube.com/watch?v=pG0QZ7OddX4) \n",
    "* History of GAN's is best explained in this [blog](https://lilianweng.github.io/posts/2017-08-20-gan/)\n",
    "* The Wasserstein Generative Adversarial Network, or WGAN for short, is an extension to the generative adversarial network that both improves the stability when training a GAN and provides a loss function that correlates with the quality of generated images.\n",
    "\n",
    "<!-- Algorithm for WGAN -->\n",
    "## Algorithm for WGAN\n",
    "1. Train the critic model for a fixed number of iterations.\n",
    "2. Update the critic model using the critic loss function.\n",
    "3. Train the generator model.\n",
    "4. Update the generator model using the generator loss function.\n",
    "\n",
    "\n",
    "* Loss function for critic model:\n",
    "    * critic_loss = -mean(critic_output_real) + mean(critic_output_fake)\n",
    "    * Basically, E[critic(real)] - E[critic(fake)] where E is the expectation, and critic tries to maximize this. But as loss is to be minimized, we take negative of it.\n",
    "    * Generator tries to minimize this loss.\n",
    "  \n",
    "* And in this model we can come to know the model generates good images by looking at the critic loss. If the critic loss is low, then the images generated are good. That is ideally the critic loss should be 0. So we train the generator to minimize the critic loss.\n",
    "\n",
    "* Loss function for generator model:\n",
    "    * generator_loss = -mean(critic_output_fake)\n",
    "    * Generator tries to maximize this loss, i.e., E[critic(fake)]. But as loss is to be minimized, we take negative of it.\n",
    "    * What this means is that the generator tries to generate images that the critic will classify as real. So, the generator tries to maximize the critic's output for fake images.\n",
    "\n",
    "\n",
    "For every n updates to the critic, we update the generator once. And n is a hyperparameter that can be tuned.\n",
    "\n",
    "* WGAN-GP is an improved version of WGAN.\n",
    "* WGAN-GP uses gradient penalty to enforce the Lipschitz constraint on the critic.\n",
    "\n",
    "* The critic is trained to output a scalar value for each input image. And the critic is trained to output a higher value for real images and a lower value for fake images.\n",
    "* And to keep the critic within the Lipschitz constraint, we add a gradient penalty term to the loss function.\n",
    "\n",
    "* What is the Lipschitz constraint?<br>\n",
    "    The Lipschitz constraint is a mathematical property that bounds the rate of change of a function. For example, for y = 2x+3, the Lipschitz constant is 2, means for increase of 1 in x, y will increase by 2.\n",
    "    In the context of GANs, the Lipschitz constraint is used to bound the rate of change of the critic. This is important because if the critic is not bounded, it can output very high values for fake images and very low values for real images, which can make the training unstable and explode the gradients.\n",
    "\n",
    "* In normal WGAN, we enforce the Lipschitz constraint by clipping the critic weights to a limited range after each mini-batch update. But this can lead to vanishing gradients and mode collapse. So, in WGAN-GP, we use gradient penalty to enforce the Lipschitz constraint without clipping the critic weights.\n",
    "\n",
    "* The gradient penalty term is calculated as the norm of the gradients of the critic with respect to the input images. This term is added to the loss function to enforce the Lipschitz constraint.\n",
    "  \n",
    "* The differences in implementation for the WGAN are as follows:\n",
    "    1. Use a linear activation function in the output layer of the critic model (instead of sigmoid).\n",
    "    2. Use -1 labels for real images and 1 labels for fake images (instead of 1 and 0).\n",
    "    3. Use Wasserstein loss to train the critic and generator models.\n",
    "    4. Constrain critic model weights to a limited range after each mini batch update (e.g. [-0.01,0.01]).\n",
    "    5. Update the critic model more times than the generator each iteration (e.g. 5).\n",
    "    6. Use the RMSProp version of gradient descent with a small learning rate and no momentum (e.g. 0.00005).\n",
    "\n",
    "What is that wgan is able to solve when compared to the previous versions like DCGAN?\n",
    "\n",
    "Wasserstein Generative Adversarial Networks (WGANs) improve upon previous versions like Deep Convolutional GANs (DCGANs) in several ways:\n",
    "\n",
    "1. Stability of Training: Traditional GANs, including DCGANs, can suffer from mode collapse and training instability. WGANs address this issue by introducing a new training objective based on Wasserstein distance (also known as Earth Mover's Distance), which provides a more stable and meaningful measure of the difference between probability distributions. This stability leads to more reliable training and fewer problems like mode collapse.\n",
    "3. Meaningful Loss Metric: In traditional GAN training, the discriminator's output doesn't necessarily correspond to meaningful probability values. In contrast, the WGAN training objective encourages the discriminator to output values that approximate the Wasserstein distance between the real and generated distributions. This leads to discriminator outputs that can be interpreted as meaningful measures of the similarity between the real and generated data distributions.\n",
    "4. Improved Gradient Flow: The WGAN training objective, based on Wasserstein distance, provides smoother gradients throughout training compared to traditional GANs. This smoother gradient flow can lead to faster convergence and more stable training dynamics.\n",
    "5. More Meaningful Generator Updates: In WGAN training, the generator is updated based on the gradients of the discriminator with respect to the generated samples. This means that the generator's updates are more directly related to how the generated samples are perceived by the discriminator, leading to more meaningful updates and potentially better sample quality.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Generator for WGAN\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the WGAN\n",
    "# Hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 1e-4\n",
    "z_dim = 100\n",
    "image_dim = 64\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "features_disc = 16\n",
    "features_gen = 16\n",
    "channels_img = 1\n",
    "critic_iter = 5\n",
    "lambda_gp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_dim),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)]\n",
    "    )\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator and discriminator\n",
    "gen = Generator(z_dim, channels_img, features_gen).to(device)\n",
    "critic = Discriminator(channels_img, features_disc).to(device)\n",
    "\n",
    "# Initialize the weights of the generator and discriminator\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "critic = critic.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimizers\n",
    "gen_opt = optim.Adam(gen.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "critic_opt = optim.Adam(critic.parameters(), lr=lr, betas=(0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gradient Penalty\n",
    "def calc_gradient_penalty(critic, real, fake, device='cpu'):\n",
    "    BATCH_SIZE, C, H, W = real.shape \n",
    "    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device) # epsilon is a random number between 0 and 1 for each image in the batch, and is repeated for each channel\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training the WGAN\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for real, _ in dataloader:\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        for _ in range(critic_iter):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(real).reshape(-1) # Flatten the critic scores for the real images\n",
    "            critic_fake = critic(fake).reshape(-1) # Flatten the critic scores for the fake images\n",
    "            gp = calc_gradient_penalty(critic, real, fake, device=device)\n",
    "            critic_loss = (\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "            ) # Maximize the critic loss so we minimize the negative of the critic loss\n",
    "            \n",
    "            # We are adding the gradient penalty to the loss in order to enforce the Lipschitz constraint, which is a key component of WGANs\n",
    "            # The Lipschitz constraint is a way to enforce that the critic (discriminator) does not become too powerful, which can lead to mode collapse\n",
    "            # The Lipschitz constraint is enforced by making sure that the gradient of the critic with respect to the input is always less than a certain value\n",
    "            # The gradient penalty is a way to enforce this constraint by adding a penalty term to the loss that penalizes the gradient of the critic with respect to the input\n",
    "            # The gradient penalty is calculated by taking the gradient of the critic scores with respect to the input images, and then taking the norm of the gradient\n",
    "            # The norm of the gradient is then squared and the mean is taken to get the gradient penalty\n",
    "            # The gradient penalty is then added to the critic loss to enforce the Lipschitz constraint\n",
    "\n",
    "            # In normal WGANs, lipshitz constraint is enforced by clipping the weights of the critic to a certain range (e.g. -0.01 to 0.01) after each update but this can lead to mode collapse and other issues\n",
    "            # The gradient penalty is a more stable way to enforce the Lipschitz constraint\n",
    "            \n",
    "            critic.zero_grad()\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "            critic_opt.step()\n",
    "\n",
    "        # Generator update\n",
    "        gen.zero_grad()\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        critic_fake = critic(fake).reshape(-1)\n",
    "        gen_loss = -torch.mean(critic_fake)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        discriminator_losses += [critic_loss.item()]\n",
    "        generator_losses += [gen_loss.item()]\n",
    "\n",
    "        # Visualization code\n",
    "        if cur_step % 500 == 0 and cur_step > 0:\n",
    "            print(\n",
    "                f\"Step {cur_step}: Generator loss: {gen_loss.item()}, discriminator loss: {critic_loss.item()}\"\n",
    "            )\n",
    "            noise = torch.randn(9, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            fake = fake.detach().cpu()\n",
    "            img_grid = torchvision.utils.make_grid(fake, nrow=3)\n",
    "            plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "            plt.show()\n",
    "\n",
    "        cur_step += 1\n",
    "\n",
    "# Save the model\n",
    "torch.save(gen.state_dict(), \"WGAN_Generator.pth\")\n",
    "torch.save(critic.state_dict(), \"WGAN_Discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(generator_losses, label='Generator Loss')\n",
    "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.title('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Even 5 epochs of training can generate good images.\n",
    "\n",
    "Results after 5 epochs of training:\n",
    "\n",
    "![image](../images/wgangp-result.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
